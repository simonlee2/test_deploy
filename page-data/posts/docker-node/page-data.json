{"componentChunkName":"component---src-templates-post-template-post-template-tsx","path":"/posts/docker-node/","result":{"data":{"markdownRemark":{"id":"8be88bfe-7194-5b02-9cee-4ff04aadda8b","html":"<p><img src=\"https://cdn-images-1.medium.com/max/1600/1*LHzc8Srf5_XBeKzNWdVnfQ.png\" alt=\"\"></p>\n<p>It all started when I asked a friend for help on a project two weeks ago. Having to set up the dev environment for every new machine is tedious and could cause issues down the road. Since I’ve been meaning to learn to use Docker, I decided to dockerize the app, which is a Node.js server and a PostgreSQL database with PostGIS extension that will serve an API for an iOS app.</p>\n<h1 id=\"let-the-journey-begin\" style=\"position:relative;\"><a href=\"#let-the-journey-begin\" aria-label=\"let the journey begin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Let the journey begin</h1>\n<h2 id=\"learn-the-basics\" style=\"position:relative;\"><a href=\"#learn-the-basics\" aria-label=\"learn the basics permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Learn the Basics</h2>\n<p><a href=\"https://docs.docker.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">The official Docker documentation</a> does a great job walking through the installation of the Docker Engine as well as explaining concepts like containers and services. I won’t repeat them here, but definitely read through the guide if you’re not familiar with Docker.</p>\n<h2 id=\"look-from-examples\" style=\"position:relative;\"><a href=\"#look-from-examples\" aria-label=\"look from examples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Look from Examples</h2>\n<p>After having a basic understanding of the concepts and tools, I looked for tutorials and projects that have a similar set up as mine. I searched for terms like “docker node postgis”, “docker node postgres”, and “docker server database” to find configurations where containers are separated by roles (app, db, etc). Most projects followed the official Docker documentation and used <code class=\"language-text\">docker-compose</code> to define the interaction among the containers.</p>\n<p>Node.js containers usually have a Dockerfile that bundles the app on top of the official Node.js image so that the app will start when the Docker Engine starts a container off of the image.\nDatabase containers are usually simple enough that the configuration is defined directly in the <code class=\"language-text\">docker-compose.yml</code> without its own <code class=\"language-text\">Dockerfile</code>. You can specify an image for the database (<code class=\"language-text\">postgres</code>, <code class=\"language-text\">mysql</code>, <code class=\"language-text\">mariadb</code>, etc), set up environment variables to configure the database, define ports and volumes for the data, and you’ll have a database container up and running.\nTo sum it up, each container could be an image from Docker Hub or a custom image defined by a <code class=\"language-text\">Dockerfile</code>. A <code class=\"language-text\">docker-compose.yml</code> for the project will orchestrate all the containers involved in the project.</p>\n<h2 id=\"dockerize-the-nodejs-server\" style=\"position:relative;\"><a href=\"#dockerize-the-nodejs-server\" aria-label=\"dockerize the nodejs server permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dockerize the Node.js server</h2>\n<p>The server can be dockerized fairly easily. The <code class=\"language-text\">Dockerfile</code> below copies the source code and runs <code class=\"language-text\">npm install</code> on the official Node.js image. The server can be run in a container with a simple <code class=\"language-text\">docker build -t server .</code> and <code class=\"language-text\">docker run -p 3000:3000 server npm start</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Dockerfile\nFROM node:7.8.0\n# install packages\nRUN mkdir -p /usr/src/app\nWORKDIR /usr/src\nCOPY package.json /usr/src\nRUN npm install\nCOPY . /usr/src\nEXPOSE 3000</code></pre></div>\n<h2 id=\"dockerize-the-database\" style=\"position:relative;\"><a href=\"#dockerize-the-database\" aria-label=\"dockerize the database permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dockerize the database</h2>\n<p>I used the <code class=\"language-text\">mdillon/postgis</code> image for PostgreSQL+PostGIS from Docker Hub at first to see if I can get the server and database up and talking to each other.</p>\n<p>Here’s what the <code class=\"language-text\">docker-compose.yml</code> looked like at this point:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># docker-compose.yml\nversion: '2'\nservices:\n    db:\n        image: mdillon/postgis\n        ports:\n            - \"5432:5432\"\n        environment:\n            - POSTGRES_USER=user\n            - POSTGRES_PASSWORD=password\n            - POSTGRES_DB=db\n    server:\n        build: server\n        depends_on:\n            - db\n        ports:\n            - \"3000:3000\"\n        command: [\"npm\", \"start\"]</code></pre></div>\n<p>Here I define a database service using a custom image that creates a PostgreSQL container with PostGIS extensions installed. The server service is built from the <code class=\"language-text\">Dockerfile</code> in the <code class=\"language-text\">server</code> directory. It is declares the database service as a dependency, so <code class=\"language-text\">docker-compose</code> will launch the <code class=\"language-text\">db</code> container before the <code class=\"language-text\">service</code> container.</p>\n<p>One caveat of the <code class=\"language-text\">depends_on</code> key is that while the dependencies will be launched first, they may not be ready by the time the server is up. In this particular case, the database service runs a series of scripts to initialize the database and install the PostGIS extensions. During the initialization, the node server may already be up and accepting connections, but the server would not be able to connect to the database.</p>\n<p>Docker has <a href=\"https://docs.docker.com/compose/startup-order/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">a page addressing the issue and possible solutions</a>. In the interest of time, I used the <a href=\"https://github.com/vishnubob/wait-for-it\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">wait-for-it</a> script that waits and checks of a TCP host/port is available. I modified the command for server to:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">command: [\"./wait-for-it.sh\", \"db:5432\", \"--\", \"npm\", \"start\"]</code></pre></div>\n<p>Now when I run <code class=\"language-text\">docker-compose up -d</code>, the server service will wait and start the server only when the database is ready to accept connections.</p>\n<h2 id=\"initialize-database\" style=\"position:relative;\"><a href=\"#initialize-database\" aria-label=\"initialize database permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Initialize Database</h2>\n<p>With the database and server set up, all that’s left is putting some data into the database to let the server do its job. Before dockerizing the app, I had two Node.js scripts for the task: one that creates the tables according to defined schemas and another one populates the database.</p>\n<p>Specifically, the the second script fetches data from a third party API, writes it out to the filesystem as a csv file, and runs <code class=\"language-text\">COPY</code> from postgres by reading the csv file. It worked well when the database and the server ran in the same environment, but wouldn’t work when the script and the database run in different containers.</p>\n<p><strong>Solution #1</strong></p>\n<p>My first idea was to handle initialization in the database container, meaning the migration and the copy scripts now have to be run there instead of the server. Unfortunately, that meant that the database container would need not only PostgreSQL and PostGIS but also Node.js. I was able to find a <a href=\"https://hub.docker.com/r/bryanburgers/node-postgres-postgis/~/dockerfile/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><code class=\"language-text\">Dockerfile</code></a> that uses parts from the official PostgreSQL image as well as the <a href=\"https://github.com/appropriate/docker-postgis\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PostGIS image from Appropriate</a>, but the resulting image size grew to just over 1GB.</p>\n<p>On top of the large image size, the database container now shares some of the code used to connect to the database from the server as well as dependencies like <a href=\"http://knexjs.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">knex</a> and <a href=\"https://github.com/jfgodoy/knex-postgis\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">knex-postgis</a>. I decided it would be a good idea to explore a different approach.</p>\n<p><strong>Solution #2</strong></p>\n<p>Instead of running the initialization in the database container just to have the script and the database in the same environment, I can create a shared volume between the two containers. The script would run on the server container, write csv file to the shared volume, and the database could read the file in the database container using the same shared volume.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># docker-compose.yml\nversion: '2'\nservices:\n    db:\n        image: mdillon/postgis\n        ports:\n            - \"5432:5432\"\n        environment:\n            - POSTGRES_USER=user\n            - POSTGRES_PASSWORD=password\n            - POSTGRES_DB=db\n        volumes:\n          - data:/usr/src/data\nserver:\n        build: server\n        depends_on:\n            - db\n        volumes:\n            - data:/usr/src/data\n        ports:\n            - \"3000:3000\"\n        command: [\"./wait-for-it.sh\", \"-t\", \"60`\", \"db:5432\", \"--\", \"npm\", \"start\"]\nvolumes:\n    data: {}</code></pre></div>\n<p>With a couple extra lines added to <code class=\"language-text\">docker-compose.yml</code>, we can easily bring up and tear down our dev environment with just a couple commands.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Bring up the containers in the background\ndocker-compose up -d\n# Run the two scripts that initializes the database\ndocker-compose run --rm server node migrate.js\ndocker-compose run --rm server node populate.js\n# Remove all containers and volumes\ndocker-compose down</code></pre></div>\n<h2 id=\"deployment\" style=\"position:relative;\"><a href=\"#deployment\" aria-label=\"deployment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deployment</h2>\n<p>It was easy to deploy to DigitalOcean, but it seems like there are two ways to do so:</p>\n<ol>\n<li><code class=\"language-text\">docker-machine</code> uses your API token from DigitalOcean to provision remote Docker hosts.</li>\n<li><code class=\"language-text\">docker-cloud</code> manages the DigitalOcean droplets through Docker Cloud</li>\n</ol>\n<p>I went with <code class=\"language-text\">docker-machine</code> and honestly the set up seems fairly straight forward. Docker has an <a href=\"https://docs.docker.com/machine/examples/ocean/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">excellent guide</a> that helped me deploy in less than half an hour.</p>\n<p>Challenges\nFinding relevant resources outside of the official documentation was one of the biggest challenges when I was learning to use Docker. Docker has gone through many releases and best practices change as features are introduced or deprecated. However, this seems to be a common theme in web development as new technologies and frameworks come and go so rapidly.</p>\n<p>It might not be a bad idea to change my default date range for search:</p>\n<p><code class=\"language-text\">https://www.google.com/search?tbs=qdr:y&amp;q={query}</code></p>\n<h2 id=\"further-improvements\" style=\"position:relative;\"><a href=\"#further-improvements\" aria-label=\"further improvements permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Further Improvements</h2>\n<p>With the current setup, I feel comfortable enough to move on and start working on the iOS client for this project. However, there are a couple thing I’d like to address down the road:</p>\n<ol>\n<li>Move database environment variables to a <code class=\"language-text\">.env</code> file. I had tried this at one point but it wasn’t starting the database properly.</li>\n<li>Is there a better way to initiate the database? Perhaps one that doesn’t involve a shared volume or manually running two scripts to populate the database?</li>\n<li>Set up continuous integration</li>\n</ol>\n<blockquote>\n<p>The article is originally posted on <a href=\"https://medium.com/@simon_lee/how-i-learned-docker-and-deployed-a-node-js-server-200e742259e5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Medium</a></p>\n</blockquote>","fields":{"slug":"/posts/docker-node/","tagSlugs":null},"frontmatter":{"date":"2017-04-28T15:09:34.000Z","description":"It all started when I asked a friend for help on a project two weeks ago. Having to set up the dev environment for every new machine is tedious and could cause issues down the road. Since I’ve been meaning to learn to use Docker, I decided to dockerize the app, which is a Node.js server and a PostgreSQL database with PostGIS extension that will serve an API for an iOS app.","tags":null,"title":"How I learned Docker and deployed a Node.js server","socialImage":null}}},"pageContext":{"slug":"/posts/docker-node/"}},"staticQueryHashes":["251939775","357378587","401334301"]}